{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-04-09T00:31:47.304770Z",
     "end_time": "2023-04-09T00:31:47.313170Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"/kesemi/g2opy/lib/\")\n",
    "\n",
    "import kesemi\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "matcher_type = \"ORB\"  # OR \"SP\", \"SG\"\n",
    "train_intrinsics = np.asarray([[481.20, 0, 319.50],\n",
    "                               [0, -480.00, 239.50],\n",
    "                               [0, 0, 1]])\n",
    "# Replace if query and training images are taken from different cameras\n",
    "query_intrinsics = train_intrinsics\n",
    "depth_scale = 5000\n",
    "\n",
    "path_to_train_depth_image = Path(\"test_images/depth/0150.png\")\n",
    "path_to_train_color_image = Path(\"test_images/rgb/0150.png\")\n",
    "path_to_query_color_image = Path(\"test_images/rgb/0200.png\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-09T00:31:47.777920Z",
     "end_time": "2023-04-09T00:31:47.783090Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if matcher_type == \"ORB\":\n",
    "    matcher = kesemi.ORB(nfeatures=1000, ratio_threshold=0.7)\n",
    "elif matcher_type == \"SP\":\n",
    "    matcher = kesemi.SuperPoint(\"superpoint_v1.pth\", nn_thresh=0.7)\n",
    "elif matcher_type == \"SG\":\n",
    "    matcher = kesemi.SuperGlue(\n",
    "        path_to_sp_weights=\"superpoint_v1.pth\",\n",
    "        path_to_sg_weights=\"superglue_indoor.pth\",\n",
    "    )\n",
    "else:\n",
    "    raise ValueError(\"Matcher type should be ORB, SuperPoint or SuperGlue\")\n",
    "\n",
    "# On some scenes, the results are better if the threshold is much higher (e.g., 20000)\n",
    "pose_optimizer = kesemi.PoseOptimizer(query_intrinsics, reproj_tresh=30)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-09T00:31:48.140704Z",
     "end_time": "2023-04-09T00:31:48.144837Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "matches, query_kpts, train_kpts = matcher.match(\n",
    "    path_to_train_color_image, path_to_query_color_image\n",
    ")\n",
    "train_depth_image = kesemi.DepthImage(\n",
    "    path_to_train_depth_image,\n",
    "    train_kpts,\n",
    "    train_intrinsics,\n",
    "    depth_scale,\n",
    ")\n",
    "matches = train_depth_image.filter_matches_with_depth_mask(matches)\n",
    "\n",
    "kpts_obs = []\n",
    "keyframe_3d_points = []\n",
    "for matched_keyframe_kp_i, matched_query_kp_i in matches:\n",
    "    keyframe_3d_points.append(train_depth_image.kpts_3d[matched_keyframe_kp_i])\n",
    "    kpts_obs.append(query_kpts[matched_query_kp_i])\n",
    "T = pose_optimizer.optimize(keyframe_3d_points, kpts_obs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-09T00:31:48.878047Z",
     "end_time": "2023-04-09T00:31:48.917799Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.savetxt(\"T.txt\", T)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
